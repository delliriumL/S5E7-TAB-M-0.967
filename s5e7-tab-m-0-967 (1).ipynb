{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6129c0f8",
   "metadata": {
    "papermill": {
     "duration": 0.004366,
     "end_time": "2025-07-06T22:05:00.897509",
     "exception": false,
     "start_time": "2025-07-06T22:05:00.893143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Goal of the competition: \n",
    "Objective is to predict whether a person is an Introvert or Extrovert, given their social behavior and personality traits.\n",
    "# Evaluation:\n",
    "Submissions are evaluated using Accuracy Score between the predicted value and the observed target.\n",
    "# Features:\n",
    "- Time_spent_Alone: Hours spent alone daily (0–11).\n",
    "- Stage_fear: Presence of stage fright (Yes/No).\n",
    "- Social_event_attendance: Frequency of social events (0–10).\n",
    "- Going_outside: Frequency of going outside (0–7).\n",
    "- Drained_after_socializing: Feeling drained after socializing (Yes/No).\n",
    "- Friends_circle_size: Number of close friends (0–15).\n",
    "- Post_frequency: Social media post frequency (0–10).\n",
    "- Personality: Target variable (Extrovert/Introvert)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a0500",
   "metadata": {
    "papermill": {
     "duration": 0.003117,
     "end_time": "2025-07-06T22:05:00.904125",
     "exception": false,
     "start_time": "2025-07-06T22:05:00.901008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " # Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a580b3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T22:05:00.911474Z",
     "iopub.status.busy": "2025-07-06T22:05:00.911226Z",
     "iopub.status.idle": "2025-07-06T22:06:19.227718Z",
     "shell.execute_reply": "2025-07-06T22:06:19.226958Z"
    },
    "papermill": {
     "duration": 78.321979,
     "end_time": "2025-07-06T22:06:19.229279",
     "exception": false,
     "start_time": "2025-07-06T22:05:00.907300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install tabm rtdl-num-embeddings -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3317c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T22:06:19.273522Z",
     "iopub.status.busy": "2025-07-06T22:06:19.272872Z",
     "iopub.status.idle": "2025-07-06T22:06:26.660923Z",
     "shell.execute_reply": "2025-07-06T22:06:26.660266Z"
    },
    "papermill": {
     "duration": 7.411104,
     "end_time": "2025-07-06T22:06:26.662317",
     "exception": false,
     "start_time": "2025-07-06T22:06:19.251213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch import Tensor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from copy import deepcopy\n",
    "import rtdl_num_embeddings\n",
    "import tabm\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4f7050",
   "metadata": {
    "papermill": {
     "duration": 0.019707,
     "end_time": "2025-07-06T22:06:26.702762",
     "exception": false,
     "start_time": "2025-07-06T22:06:26.683055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the data\n",
    "We load the main training/test datasets provided by the competition, as well as an external dataset (personality_datasert.csv) to enhance model generalization. This external data will later be upsampled and merged with the original training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ada83d0b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-06T22:06:26.743689Z",
     "iopub.status.busy": "2025-07-06T22:06:26.743075Z",
     "iopub.status.idle": "2025-07-06T22:06:26.809006Z",
     "shell.execute_reply": "2025-07-06T22:06:26.808280Z"
    },
    "papermill": {
     "duration": 0.087991,
     "end_time": "2025-07-06T22:06:26.810236",
     "exception": false,
     "start_time": "2025-07-06T22:06:26.722245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/playground-series-s5e7/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s5e7/test.csv')\n",
    "original = pd.read_csv('/kaggle/input/extrovert-vs-introvert-behavior-data/personality_datasert.csv')\n",
    "sample_submission = pd.read_csv('/kaggle/input/playground-series-s5e7/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8045dccf",
   "metadata": {
    "papermill": {
     "duration": 0.020172,
     "end_time": "2025-07-06T22:06:26.851498",
     "exception": false,
     "start_time": "2025-07-06T22:06:26.831326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing and data augmentation\n",
    "We boost the external dataset to provide more examples and better regularization.\n",
    "Feature columns are isolated for training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eca759fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T22:06:26.894058Z",
     "iopub.status.busy": "2025-07-06T22:06:26.893479Z",
     "iopub.status.idle": "2025-07-06T22:06:26.916036Z",
     "shell.execute_reply": "2025-07-06T22:06:26.915313Z"
    },
    "papermill": {
     "duration": 0.044733,
     "end_time": "2025-07-06T22:06:26.917151",
     "exception": false,
     "start_time": "2025-07-06T22:06:26.872418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic split of features and targets\n",
    "X_train = train.drop(['id', 'Personality'], axis=1, errors='ignore')\n",
    "y_train = train['Personality']\n",
    "X_test = test.drop(['id'], axis=1, errors='ignore')\n",
    "\n",
    "# Multiply external dataset (data augmentation)\n",
    "original_copy = original.copy()\n",
    "for _ in range(7):  # 1 original + 7 copies = x8 total\n",
    "    original = pd.concat([original, original_copy], axis=0, ignore_index=True)\n",
    "\n",
    "X_original = original.drop(['id', 'Personality'], axis=1, errors='ignore')\n",
    "y_original = original['Personality']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb01a7c",
   "metadata": {
    "papermill": {
     "duration": 0.019808,
     "end_time": "2025-07-06T22:06:26.956742",
     "exception": false,
     "start_time": "2025-07-06T22:06:26.936934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Encode categorical variables\n",
    "Converts categorical values into numeric IDs using LabelEncoder.\n",
    "Same encoder used for all sources to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bbc965d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T22:06:27.044168Z",
     "iopub.status.busy": "2025-07-06T22:06:27.043672Z",
     "iopub.status.idle": "2025-07-06T22:06:27.078619Z",
     "shell.execute_reply": "2025-07-06T22:06:27.078069Z"
    },
    "papermill": {
     "duration": 0.103128,
     "end_time": "2025-07-06T22:06:27.079625",
     "exception": false,
     "start_time": "2025-07-06T22:06:26.976497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Detect categorical columns\n",
    "cat_cols = X_train.select_dtypes(include='object').columns\n",
    "label_encoders = {}\n",
    "\n",
    "# Apply label encoding to all categorical features\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    all_data = pd.concat([X_train[col], X_test[col], X_original[col]])\n",
    "    le.fit(all_data.astype(str))\n",
    "    X_train[col] = le.transform(X_train[col].astype(str))\n",
    "    X_test[col] = le.transform(X_test[col].astype(str))\n",
    "    X_original[col] = le.transform(X_original[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode the target\n",
    "target_encoder = LabelEncoder()\n",
    "y_train = target_encoder.fit_transform(y_train)\n",
    "y_original = target_encoder.transform(y_original)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d6dccd",
   "metadata": {
    "papermill": {
     "duration": 0.019673,
     "end_time": "2025-07-06T22:06:27.119432",
     "exception": false,
     "start_time": "2025-07-06T22:06:27.099759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Combine and normalize features\n",
    "Combines and cleans all feature data for unified model input.\n",
    "Missing and infinite values are replaced with safe defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "931c59dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T22:06:27.160298Z",
     "iopub.status.busy": "2025-07-06T22:06:27.159760Z",
     "iopub.status.idle": "2025-07-06T22:06:27.178588Z",
     "shell.execute_reply": "2025-07-06T22:06:27.178043Z"
    },
    "papermill": {
     "duration": 0.040511,
     "end_time": "2025-07-06T22:06:27.179745",
     "exception": false,
     "start_time": "2025-07-06T22:06:27.139234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine training and external data\n",
    "X_all_df = pd.concat([X_train, X_original], axis=0)\n",
    "feature_names = X_all_df.columns.tolist()\n",
    "\n",
    "# Convert to float32 and align test columns\n",
    "X_all = X_all_df.astype(np.float32)\n",
    "X_test = X_test[feature_names].astype(np.float32)\n",
    "y_all = np.concatenate([y_train, y_original]).astype(np.int64)\n",
    "\n",
    "# Replace NaNs and Infs\n",
    "X_all = np.nan_to_num(X_all, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "X_test = np.nan_to_num(X_test, nan=0.0, posinf=1e6, neginf=-1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4737810",
   "metadata": {
    "papermill": {
     "duration": 0.019775,
     "end_time": "2025-07-06T22:06:27.219567",
     "exception": false,
     "start_time": "2025-07-06T22:06:27.199792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Split into train/val/oof\n",
    "Stratified splitting to preserve class balance in training/validation sets.\n",
    "Holdout set used for final unbiased evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c028ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T22:06:27.260149Z",
     "iopub.status.busy": "2025-07-06T22:06:27.259947Z",
     "iopub.status.idle": "2025-07-06T22:06:27.284635Z",
     "shell.execute_reply": "2025-07-06T22:06:27.284148Z"
    },
    "papermill": {
     "duration": 0.046003,
     "end_time": "2025-07-06T22:06:27.285644",
     "exception": false,
     "start_time": "2025-07-06T22:06:27.239641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Holdout 15% of data for final validation\n",
    "trainval_idx, oof_idx = train_test_split(\n",
    "    np.arange(len(y_all)), train_size=0.85, stratify=y_all, random_state=42\n",
    ")\n",
    "\n",
    "# Further split trainval into train and val\n",
    "train_idx, val_idx = train_test_split(\n",
    "    trainval_idx, train_size=0.85, stratify=y_all[trainval_idx], random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4906ee",
   "metadata": {
    "papermill": {
     "duration": 0.021244,
     "end_time": "2025-07-06T22:06:27.326791",
     "exception": false,
     "start_time": "2025-07-06T22:06:27.305547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Convert to PyTorch tensors\n",
    "Converts NumPy arrays into GPU-ready PyTorch tensors for efficient training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b68654ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T22:06:27.366702Z",
     "iopub.status.busy": "2025-07-06T22:06:27.366463Z",
     "iopub.status.idle": "2025-07-06T22:06:27.621004Z",
     "shell.execute_reply": "2025-07-06T22:06:27.620206Z"
    },
    "papermill": {
     "duration": 0.276248,
     "end_time": "2025-07-06T22:06:27.622454",
     "exception": false,
     "start_time": "2025-07-06T22:06:27.346206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_numpy = {\n",
    "    'train': {'x_num': X_all[train_idx], 'y': y_all[train_idx]},\n",
    "    'val': {'x_num': X_all[val_idx], 'y': y_all[val_idx]},\n",
    "    'oof': {'x_num': X_all[oof_idx], 'y': y_all[oof_idx]},\n",
    "    'test': {'x_num': X_test, 'y': np.zeros(len(X_test), dtype=np.int64)}\n",
    "}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = {\n",
    "    part: {k: torch.tensor(v, device=device) for k, v in d.items()}\n",
    "    for part, d in data_numpy.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cd6e63",
   "metadata": {
    "papermill": {
     "duration": 0.019901,
     "end_time": "2025-07-06T22:06:27.662806",
     "exception": false,
     "start_time": "2025-07-06T22:06:27.642905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Numerical embeddings\n",
    "Applies piecewise linear embedding on numeric inputs using RTDL.\n",
    "Helps the model handle numeric features more expressively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2546b6ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T22:06:27.702786Z",
     "iopub.status.busy": "2025-07-06T22:06:27.702532Z",
     "iopub.status.idle": "2025-07-06T22:06:28.326345Z",
     "shell.execute_reply": "2025-07-06T22:06:28.325795Z"
    },
    "papermill": {
     "duration": 0.645428,
     "end_time": "2025-07-06T22:06:28.327697",
     "exception": false,
     "start_time": "2025-07-06T22:06:27.682269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_bins_input = torch.nan_to_num(data['train']['x_num'], nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "num_embeddings = rtdl_num_embeddings.PiecewiseLinearEmbeddings(\n",
    "    rtdl_num_embeddings.compute_bins(X_bins_input, n_bins=32),\n",
    "    d_embedding=32,\n",
    "    activation=False,\n",
    "    version='B'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb91b6da",
   "metadata": {
    "papermill": {
     "duration": 0.019998,
     "end_time": "2025-07-06T22:06:28.368192",
     "exception": false,
     "start_time": "2025-07-06T22:06:28.348194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build TabM model\n",
    "Builds and compiles the TabM architecture with dropout and RMSprop optimizer.\n",
    "k=4 determines number of passes (attention hops)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2959c136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T22:06:28.409228Z",
     "iopub.status.busy": "2025-07-06T22:06:28.408986Z",
     "iopub.status.idle": "2025-07-06T22:06:33.089750Z",
     "shell.execute_reply": "2025-07-06T22:06:33.089119Z"
    },
    "papermill": {
     "duration": 4.702699,
     "end_time": "2025-07-06T22:06:33.091157",
     "exception": false,
     "start_time": "2025-07-06T22:06:28.388458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tabm.TabM.make(\n",
    "    n_num_features=X_all.shape[1],\n",
    "    d_out=len(np.unique(y_all)),\n",
    "    cat_cardinalities=[],\n",
    "    num_embeddings=num_embeddings,\n",
    "    k=4,\n",
    "    dropout=0.35\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=3e-3, alpha=0.99)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa334aa",
   "metadata": {
    "papermill": {
     "duration": 0.019761,
     "end_time": "2025-07-06T22:06:33.131659",
     "exception": false,
     "start_time": "2025-07-06T22:06:33.111898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Define loss and evaluation\n",
    "Custom loss with class balancing.\n",
    "Evaluation uses macro-F1 and accuracy averaged across batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f02dc48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T22:06:33.172382Z",
     "iopub.status.busy": "2025-07-06T22:06:33.172028Z",
     "iopub.status.idle": "2025-07-06T22:06:33.178320Z",
     "shell.execute_reply": "2025-07-06T22:06:33.177825Z"
    },
    "papermill": {
     "duration": 0.028034,
     "end_time": "2025-07-06T22:06:33.179388",
     "exception": false,
     "start_time": "2025-07-06T22:06:33.151354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_CLASS_WEIGHTS = False  # Toggle class weights for cross-entropy\n",
    "\n",
    "if USE_CLASS_WEIGHTS:\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_all), y=y_all)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32, device=device)\n",
    "else:\n",
    "    class_weights = None\n",
    "\n",
    "def loss_fn(y_pred: Tensor, y_true: Tensor) -> Tensor:\n",
    "    y_pred = y_pred.flatten(0, 1)\n",
    "    y_true = y_true.repeat_interleave(model.backbone.k)\n",
    "    return F.cross_entropy(y_pred, y_true, weight=class_weights)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(part: str) -> tuple[float, float]:\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    for i in torch.arange(len(data[part]['y']), device=device).split(1024):\n",
    "        out = model(data[part]['x_num'][i])\n",
    "        out = torch.softmax(out, dim=-1).float().mean(1)\n",
    "        y_pred.append(out)\n",
    "    y_pred = torch.cat(y_pred).cpu().numpy()\n",
    "    y_true = data_numpy[part]['y']\n",
    "    f1 = f1_score(y_true, y_pred.argmax(1), average='macro')\n",
    "    acc = accuracy_score(y_true, y_pred.argmax(1))\n",
    "    return f1, acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0360cfa",
   "metadata": {
    "papermill": {
     "duration": 0.020464,
     "end_time": "2025-07-06T22:06:33.219935",
     "exception": false,
     "start_time": "2025-07-06T22:06:33.199471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train the model\n",
    "Trains the model with early stopping on validation accuracy.\n",
    "Tracks best weights across epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "592bda89",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-06T22:06:33.261339Z",
     "iopub.status.busy": "2025-07-06T22:06:33.261123Z",
     "iopub.status.idle": "2025-07-06T22:07:31.844467Z",
     "shell.execute_reply": "2025-07-06T22:07:31.843400Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 58.60584,
     "end_time": "2025-07-06T22:07:31.846007",
     "exception": false,
     "start_time": "2025-07-06T22:06:33.240167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | train Loss: 49.2615 | val Acc: 0.9523 | val F1: 0.9497\n",
      "Epoch 001 | train Loss: 24.4237 | val Acc: 0.9523 | val F1: 0.9497\n",
      "Epoch 002 | train Loss: 23.8409 | val Acc: 0.9523 | val F1: 0.9497\n",
      "Epoch 003 | train Loss: 23.4957 | val Acc: 0.9523 | val F1: 0.9497\n",
      "Epoch 004 | train Loss: 23.1608 | val Acc: 0.9523 | val F1: 0.9497\n",
      "Epoch 005 | train Loss: 22.9285 | val Acc: 0.9523 | val F1: 0.9497\n",
      "Epoch 006 | train Loss: 22.6133 | val Acc: 0.9523 | val F1: 0.9497\n",
      "Epoch 007 | train Loss: 22.4188 | val Acc: 0.9523 | val F1: 0.9497\n",
      "Epoch 008 | train Loss: 22.1219 | val Acc: 0.9523 | val F1: 0.9497\n",
      "Epoch 009 | train Loss: 21.7838 | val Acc: 0.9523 | val F1: 0.9497\n",
      "Epoch 010 | train Loss: 21.8509 | val Acc: 0.9523 | val F1: 0.9497\n",
      "Epoch 011 | train Loss: 21.4999 | val Acc: 0.9523 | val F1: 0.9497\n",
      "Epoch 012 | train Loss: 21.3597 | val Acc: 0.9523 | val F1: 0.9497\n",
      "Epoch 013 | train Loss: 21.0659 | val Acc: 0.9523 | val F1: 0.9497\n",
      "Epoch 014 | train Loss: 20.9367 | val Acc: 0.9524 | val F1: 0.9499\n",
      "Epoch 015 | train Loss: 20.6974 | val Acc: 0.9526 | val F1: 0.9501\n",
      "Epoch 016 | train Loss: 20.4685 | val Acc: 0.9523 | val F1: 0.9497\n",
      "Epoch 017 | train Loss: 20.2741 | val Acc: 0.9530 | val F1: 0.9505\n",
      "Epoch 018 | train Loss: 20.0173 | val Acc: 0.9528 | val F1: 0.9503\n",
      "Epoch 019 | train Loss: 19.8666 | val Acc: 0.9526 | val F1: 0.9502\n",
      "Epoch 020 | train Loss: 19.6235 | val Acc: 0.9526 | val F1: 0.9501\n",
      "Epoch 021 | train Loss: 19.4387 | val Acc: 0.9526 | val F1: 0.9501\n",
      "Epoch 022 | train Loss: 19.1535 | val Acc: 0.9526 | val F1: 0.9501\n",
      "Epoch 023 | train Loss: 18.8197 | val Acc: 0.9528 | val F1: 0.9504\n",
      "Epoch 024 | train Loss: 18.5348 | val Acc: 0.9524 | val F1: 0.9500\n",
      "Epoch 025 | train Loss: 18.3885 | val Acc: 0.9532 | val F1: 0.9508\n",
      "Epoch 026 | train Loss: 17.9476 | val Acc: 0.9526 | val F1: 0.9502\n",
      "Epoch 027 | train Loss: 17.8115 | val Acc: 0.9526 | val F1: 0.9502\n",
      "Epoch 028 | train Loss: 17.4304 | val Acc: 0.9536 | val F1: 0.9511\n",
      "Epoch 029 | train Loss: 17.1826 | val Acc: 0.9541 | val F1: 0.9518\n",
      "Epoch 030 | train Loss: 17.1159 | val Acc: 0.9568 | val F1: 0.9546\n",
      "Epoch 031 | train Loss: 16.7353 | val Acc: 0.9560 | val F1: 0.9538\n",
      "Epoch 032 | train Loss: 16.4388 | val Acc: 0.9549 | val F1: 0.9525\n",
      "Epoch 033 | train Loss: 16.1033 | val Acc: 0.9555 | val F1: 0.9531\n",
      "Epoch 034 | train Loss: 15.8604 | val Acc: 0.9573 | val F1: 0.9552\n",
      "Epoch 035 | train Loss: 15.7753 | val Acc: 0.9545 | val F1: 0.9521\n",
      "Epoch 036 | train Loss: 15.4950 | val Acc: 0.9556 | val F1: 0.9534\n",
      "Epoch 037 | train Loss: 15.1765 | val Acc: 0.9586 | val F1: 0.9566\n",
      "Epoch 038 | train Loss: 14.9936 | val Acc: 0.9562 | val F1: 0.9540\n",
      "Epoch 039 | train Loss: 14.7839 | val Acc: 0.9585 | val F1: 0.9563\n",
      "Epoch 040 | train Loss: 14.5671 | val Acc: 0.9586 | val F1: 0.9565\n",
      "Epoch 041 | train Loss: 14.3792 | val Acc: 0.9607 | val F1: 0.9587\n",
      "Epoch 042 | train Loss: 14.1490 | val Acc: 0.9602 | val F1: 0.9580\n",
      "Epoch 043 | train Loss: 13.9690 | val Acc: 0.9592 | val F1: 0.9572\n",
      "Epoch 044 | train Loss: 13.8342 | val Acc: 0.9615 | val F1: 0.9595\n",
      "Epoch 045 | train Loss: 13.9093 | val Acc: 0.9598 | val F1: 0.9577\n",
      "Epoch 046 | train Loss: 13.5438 | val Acc: 0.9609 | val F1: 0.9588\n",
      "Epoch 047 | train Loss: 13.3153 | val Acc: 0.9605 | val F1: 0.9584\n",
      "Epoch 048 | train Loss: 13.4675 | val Acc: 0.9605 | val F1: 0.9585\n",
      "Epoch 049 | train Loss: 13.0699 | val Acc: 0.9609 | val F1: 0.9589\n",
      "Epoch 050 | train Loss: 13.2699 | val Acc: 0.9632 | val F1: 0.9612\n",
      "Epoch 051 | train Loss: 12.7607 | val Acc: 0.9647 | val F1: 0.9628\n",
      "Epoch 052 | train Loss: 12.8721 | val Acc: 0.9648 | val F1: 0.9630\n",
      "Epoch 053 | train Loss: 12.5781 | val Acc: 0.9622 | val F1: 0.9602\n",
      "Epoch 054 | train Loss: 12.5202 | val Acc: 0.9588 | val F1: 0.9566\n",
      "Epoch 055 | train Loss: 12.4536 | val Acc: 0.9620 | val F1: 0.9599\n",
      "Epoch 056 | train Loss: 12.4572 | val Acc: 0.9624 | val F1: 0.9604\n",
      "Epoch 057 | train Loss: 12.4073 | val Acc: 0.9626 | val F1: 0.9606\n",
      "Epoch 058 | train Loss: 12.1581 | val Acc: 0.9626 | val F1: 0.9607\n",
      "Epoch 059 | train Loss: 11.9819 | val Acc: 0.9639 | val F1: 0.9621\n",
      "Epoch 060 | train Loss: 12.0616 | val Acc: 0.9613 | val F1: 0.9590\n",
      "Epoch 061 | train Loss: 11.9508 | val Acc: 0.9624 | val F1: 0.9605\n",
      "Epoch 062 | train Loss: 11.8793 | val Acc: 0.9656 | val F1: 0.9637\n",
      "Epoch 063 | train Loss: 11.7901 | val Acc: 0.9633 | val F1: 0.9612\n",
      "Epoch 064 | train Loss: 11.8229 | val Acc: 0.9626 | val F1: 0.9605\n",
      "Epoch 065 | train Loss: 11.6309 | val Acc: 0.9635 | val F1: 0.9616\n",
      "Epoch 066 | train Loss: 11.6345 | val Acc: 0.9633 | val F1: 0.9613\n",
      "Epoch 067 | train Loss: 11.5146 | val Acc: 0.9647 | val F1: 0.9628\n",
      "Epoch 068 | train Loss: 11.4432 | val Acc: 0.9652 | val F1: 0.9634\n",
      "Epoch 069 | train Loss: 11.4628 | val Acc: 0.9628 | val F1: 0.9607\n",
      "Epoch 070 | train Loss: 11.4533 | val Acc: 0.9648 | val F1: 0.9629\n",
      "Epoch 071 | train Loss: 11.1333 | val Acc: 0.9637 | val F1: 0.9617\n",
      "Epoch 072 | train Loss: 11.3659 | val Acc: 0.9643 | val F1: 0.9623\n",
      "Epoch 073 | train Loss: 11.1833 | val Acc: 0.9648 | val F1: 0.9630\n",
      "Epoch 074 | train Loss: 11.1428 | val Acc: 0.9654 | val F1: 0.9636\n",
      "Epoch 075 | train Loss: 11.1848 | val Acc: 0.9632 | val F1: 0.9612\n",
      "Epoch 076 | train Loss: 10.9604 | val Acc: 0.9626 | val F1: 0.9606\n",
      "Epoch 077 | train Loss: 11.0262 | val Acc: 0.9654 | val F1: 0.9635\n",
      "Epoch 078 | train Loss: 10.7593 | val Acc: 0.9650 | val F1: 0.9631\n",
      "Epoch 079 | train Loss: 10.8493 | val Acc: 0.9645 | val F1: 0.9625\n",
      "Epoch 080 | train Loss: 11.0383 | val Acc: 0.9637 | val F1: 0.9617\n",
      "Epoch 081 | train Loss: 10.8579 | val Acc: 0.9637 | val F1: 0.9616\n",
      "Epoch 082 | train Loss: 10.7415 | val Acc: 0.9641 | val F1: 0.9621\n",
      "Epoch 083 | train Loss: 10.6750 | val Acc: 0.9641 | val F1: 0.9621\n",
      "Epoch 084 | train Loss: 10.5975 | val Acc: 0.9660 | val F1: 0.9640\n",
      "Epoch 085 | train Loss: 10.4585 | val Acc: 0.9643 | val F1: 0.9622\n",
      "Epoch 086 | train Loss: 10.7630 | val Acc: 0.9626 | val F1: 0.9604\n",
      "Epoch 087 | train Loss: 10.6413 | val Acc: 0.9664 | val F1: 0.9643\n",
      "Epoch 088 | train Loss: 10.4331 | val Acc: 0.9643 | val F1: 0.9623\n",
      "Epoch 089 | train Loss: 10.3135 | val Acc: 0.9633 | val F1: 0.9612\n",
      "Epoch 090 | train Loss: 10.3786 | val Acc: 0.9656 | val F1: 0.9637\n",
      "Epoch 091 | train Loss: 10.3141 | val Acc: 0.9658 | val F1: 0.9639\n",
      "Epoch 092 | train Loss: 10.4730 | val Acc: 0.9658 | val F1: 0.9640\n",
      "Epoch 093 | train Loss: 10.3362 | val Acc: 0.9660 | val F1: 0.9641\n",
      "Epoch 094 | train Loss: 10.3019 | val Acc: 0.9652 | val F1: 0.9633\n",
      "Epoch 095 | train Loss: 10.1880 | val Acc: 0.9647 | val F1: 0.9627\n",
      "Epoch 096 | train Loss: 10.2088 | val Acc: 0.9643 | val F1: 0.9623\n",
      "Epoch 097 | train Loss: 10.1470 | val Acc: 0.9637 | val F1: 0.9616\n",
      "Epoch 098 | train Loss: 10.0784 | val Acc: 0.9618 | val F1: 0.9597\n",
      "Epoch 099 | train Loss: 10.3919 | val Acc: 0.9662 | val F1: 0.9644\n",
      "Epoch 100 | train Loss: 10.0479 | val Acc: 0.9671 | val F1: 0.9652\n",
      "Epoch 101 | train Loss: 10.2005 | val Acc: 0.9643 | val F1: 0.9623\n",
      "Epoch 102 | train Loss: 10.0171 | val Acc: 0.9656 | val F1: 0.9637\n",
      "Epoch 103 | train Loss: 10.2139 | val Acc: 0.9645 | val F1: 0.9626\n",
      "Epoch 104 | train Loss: 10.1089 | val Acc: 0.9643 | val F1: 0.9622\n",
      "Epoch 105 | train Loss: 9.9559 | val Acc: 0.9669 | val F1: 0.9650\n",
      "Epoch 106 | train Loss: 9.9150 | val Acc: 0.9662 | val F1: 0.9642\n",
      "Epoch 107 | train Loss: 10.0275 | val Acc: 0.9660 | val F1: 0.9640\n",
      "Epoch 108 | train Loss: 9.9713 | val Acc: 0.9669 | val F1: 0.9651\n",
      "Epoch 109 | train Loss: 9.9145 | val Acc: 0.9658 | val F1: 0.9638\n",
      "Epoch 110 | train Loss: 9.8410 | val Acc: 0.9656 | val F1: 0.9635\n",
      "Epoch 111 | train Loss: 9.9310 | val Acc: 0.9677 | val F1: 0.9659\n",
      "Epoch 112 | train Loss: 9.7574 | val Acc: 0.9671 | val F1: 0.9653\n",
      "Epoch 113 | train Loss: 9.6847 | val Acc: 0.9654 | val F1: 0.9634\n",
      "Epoch 114 | train Loss: 9.9313 | val Acc: 0.9654 | val F1: 0.9634\n",
      "Epoch 115 | train Loss: 9.6956 | val Acc: 0.9673 | val F1: 0.9655\n",
      "Epoch 116 | train Loss: 9.7907 | val Acc: 0.9671 | val F1: 0.9653\n",
      "Epoch 117 | train Loss: 9.7270 | val Acc: 0.9665 | val F1: 0.9648\n",
      "Epoch 118 | train Loss: 9.7625 | val Acc: 0.9665 | val F1: 0.9649\n",
      "Epoch 119 | train Loss: 9.6306 | val Acc: 0.9669 | val F1: 0.9651\n",
      "Epoch 120 | train Loss: 9.7589 | val Acc: 0.9677 | val F1: 0.9659\n",
      "Epoch 121 | train Loss: 9.6972 | val Acc: 0.9635 | val F1: 0.9613\n",
      "Epoch 122 | train Loss: 9.7069 | val Acc: 0.9658 | val F1: 0.9638\n",
      "Epoch 123 | train Loss: 9.8041 | val Acc: 0.9671 | val F1: 0.9652\n",
      "Epoch 124 | train Loss: 9.5692 | val Acc: 0.9648 | val F1: 0.9628\n",
      "Epoch 125 | train Loss: 9.3723 | val Acc: 0.9650 | val F1: 0.9632\n",
      "Epoch 126 | train Loss: 9.5832 | val Acc: 0.9664 | val F1: 0.9645\n",
      "Epoch 127 | train Loss: 9.6795 | val Acc: 0.9677 | val F1: 0.9659\n",
      "Epoch 128 | train Loss: 9.4897 | val Acc: 0.9692 | val F1: 0.9675\n",
      "Epoch 129 | train Loss: 9.5649 | val Acc: 0.9641 | val F1: 0.9619\n",
      "Epoch 130 | train Loss: 9.5290 | val Acc: 0.9677 | val F1: 0.9660\n",
      "Epoch 131 | train Loss: 9.6589 | val Acc: 0.9692 | val F1: 0.9676\n",
      "Epoch 132 | train Loss: 9.5546 | val Acc: 0.9648 | val F1: 0.9629\n",
      "Epoch 133 | train Loss: 9.4207 | val Acc: 0.9622 | val F1: 0.9599\n",
      "Epoch 134 | train Loss: 9.6924 | val Acc: 0.9673 | val F1: 0.9653\n",
      "Epoch 135 | train Loss: 9.1222 | val Acc: 0.9669 | val F1: 0.9651\n",
      "Epoch 136 | train Loss: 9.3972 | val Acc: 0.9652 | val F1: 0.9632\n",
      "Epoch 137 | train Loss: 9.6068 | val Acc: 0.9671 | val F1: 0.9652\n",
      "Epoch 138 | train Loss: 9.3472 | val Acc: 0.9669 | val F1: 0.9650\n",
      "Epoch 139 | train Loss: 9.2021 | val Acc: 0.9658 | val F1: 0.9638\n",
      "Epoch 140 | train Loss: 9.3338 | val Acc: 0.9669 | val F1: 0.9650\n",
      "Epoch 141 | train Loss: 9.4923 | val Acc: 0.9654 | val F1: 0.9634\n",
      "Epoch 142 | train Loss: 9.4223 | val Acc: 0.9669 | val F1: 0.9651\n",
      "Epoch 143 | train Loss: 9.4967 | val Acc: 0.9660 | val F1: 0.9640\n",
      "Epoch 144 | train Loss: 9.2074 | val Acc: 0.9654 | val F1: 0.9634\n",
      "Epoch 145 | train Loss: 9.3400 | val Acc: 0.9656 | val F1: 0.9636\n",
      "Epoch 146 | train Loss: 9.3782 | val Acc: 0.9665 | val F1: 0.9647\n",
      "Epoch 147 | train Loss: 9.3449 | val Acc: 0.9669 | val F1: 0.9650\n",
      "Epoch 148 | train Loss: 9.2887 | val Acc: 0.9645 | val F1: 0.9624\n",
      "Epoch 149 | train Loss: 9.3813 | val Acc: 0.9665 | val F1: 0.9646\n",
      "Epoch 150 | train Loss: 9.1813 | val Acc: 0.9647 | val F1: 0.9626\n",
      "Epoch 151 | train Loss: 9.4101 | val Acc: 0.9667 | val F1: 0.9649\n",
      "Epoch 152 | train Loss: 9.1668 | val Acc: 0.9677 | val F1: 0.9658\n",
      "Epoch 153 | train Loss: 9.3396 | val Acc: 0.9667 | val F1: 0.9649\n",
      "Epoch 154 | train Loss: 9.2327 | val Acc: 0.9675 | val F1: 0.9657\n",
      "Epoch 155 | train Loss: 9.1913 | val Acc: 0.9679 | val F1: 0.9661\n",
      "Epoch 156 | train Loss: 9.2775 | val Acc: 0.9675 | val F1: 0.9656\n",
      "Epoch 157 | train Loss: 9.1705 | val Acc: 0.9641 | val F1: 0.9620\n",
      "Epoch 158 | train Loss: 9.1885 | val Acc: 0.9690 | val F1: 0.9673\n",
      "Epoch 159 | train Loss: 9.1636 | val Acc: 0.9675 | val F1: 0.9657\n",
      "Epoch 160 | train Loss: 9.0507 | val Acc: 0.9686 | val F1: 0.9669\n",
      "Epoch 161 | train Loss: 9.2762 | val Acc: 0.9669 | val F1: 0.9651\n",
      "Epoch 162 | train Loss: 9.2022 | val Acc: 0.9648 | val F1: 0.9628\n",
      "Epoch 163 | train Loss: 9.1046 | val Acc: 0.9647 | val F1: 0.9626\n",
      "Epoch 164 | train Loss: 9.0612 | val Acc: 0.9673 | val F1: 0.9656\n",
      "Epoch 165 | train Loss: 9.2662 | val Acc: 0.9680 | val F1: 0.9662\n",
      "Epoch 166 | train Loss: 9.1224 | val Acc: 0.9671 | val F1: 0.9652\n",
      "Epoch 167 | train Loss: 8.9644 | val Acc: 0.9665 | val F1: 0.9647\n",
      "Epoch 168 | train Loss: 8.8655 | val Acc: 0.9665 | val F1: 0.9647\n",
      "Epoch 169 | train Loss: 9.1714 | val Acc: 0.9686 | val F1: 0.9669\n",
      "Epoch 170 | train Loss: 9.0443 | val Acc: 0.9658 | val F1: 0.9638\n",
      "Epoch 171 | train Loss: 8.8859 | val Acc: 0.9662 | val F1: 0.9642\n",
      "Epoch 172 | train Loss: 9.0923 | val Acc: 0.9667 | val F1: 0.9648\n",
      "Epoch 173 | train Loss: 9.0804 | val Acc: 0.9667 | val F1: 0.9648\n",
      "Epoch 174 | train Loss: 8.7841 | val Acc: 0.9665 | val F1: 0.9647\n",
      "Epoch 175 | train Loss: 8.9860 | val Acc: 0.9686 | val F1: 0.9670\n",
      "Epoch 176 | train Loss: 8.8069 | val Acc: 0.9686 | val F1: 0.9669\n",
      "Epoch 177 | train Loss: 9.1375 | val Acc: 0.9677 | val F1: 0.9659\n",
      "Epoch 178 | train Loss: 8.8568 | val Acc: 0.9675 | val F1: 0.9657\n"
     ]
    }
   ],
   "source": [
    "Y_train = data['train']['y']\n",
    "train_size = len(Y_train)\n",
    "batch_size = 256\n",
    "patience = 50\n",
    "remaining_patience = patience\n",
    "best_score = -math.inf\n",
    "best_weights = deepcopy(model.state_dict())\n",
    "\n",
    "for epoch in range(450):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for idx in torch.randperm(train_size, device=device).split(batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data['train']['x_num'][idx])\n",
    "        loss = loss_fn(out, Y_train[idx])\n",
    "        if not torch.isfinite(loss):\n",
    "            print(\"NaN in loss — breaking.\")\n",
    "            break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    val_f1, val_acc = evaluate('val')\n",
    "\n",
    "    print(f\"Epoch {epoch:03} | train Loss: {total_loss:.4f} | val Acc: {val_acc:.4f} | val F1: {val_f1:.4f}\")\n",
    "    \n",
    "    if val_acc > best_score:\n",
    "        best_score = val_acc\n",
    "        best_weights = deepcopy(model.state_dict())\n",
    "        remaining_patience = patience\n",
    "    else:\n",
    "        remaining_patience -= 1\n",
    "\n",
    "    if remaining_patience == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9920d2f",
   "metadata": {
    "papermill": {
     "duration": 0.029423,
     "end_time": "2025-07-06T22:07:31.908860",
     "exception": false,
     "start_time": "2025-07-06T22:07:31.879437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Final inference & submission\n",
    "Generates predictions for test data and saves them in the required submission format.\n",
    "Also reports the model’s true performance on holdout data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "737a1a63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T22:07:31.966738Z",
     "iopub.status.busy": "2025-07-06T22:07:31.966449Z",
     "iopub.status.idle": "2025-07-06T22:07:32.016258Z",
     "shell.execute_reply": "2025-07-06T22:07:32.015433Z"
    },
    "papermill": {
     "duration": 0.079424,
     "end_time": "2025-07-06T22:07:32.017339",
     "exception": false,
     "start_time": "2025-07-06T22:07:31.937915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL HOLDOUT (OOF) — Acc: 0.9704 | F1: 0.9689\n",
      "Submission ready: submission_tabm_final.csv\n"
     ]
    }
   ],
   "source": [
    "# Load best weights and predict test set\n",
    "model.load_state_dict(best_weights)\n",
    "model.eval()\n",
    "\n",
    "x_test = data['test']['x_num'].float()\n",
    "final_preds = torch.softmax(model(x_test), dim=-1).float().mean(1)\n",
    "preds_labels = final_preds.argmax(1).cpu().numpy()\n",
    "\n",
    "# Evaluate on holdout (honest test)\n",
    "oof_f1, oof_acc = evaluate('oof')\n",
    "print(f\"FINAL HOLDOUT (OOF) — Acc: {oof_acc:.4f} | F1: {oof_f1:.4f}\")\n",
    "\n",
    "# Create final submission\n",
    "submission = sample_submission.copy()\n",
    "submission['Personality'] = target_encoder.inverse_transform(preds_labels)\n",
    "submission.to_csv('submission_tabm_final.csv', index=False)\n",
    "print(\"Submission ready: submission_tabm_final.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12738969,
     "sourceId": 91718,
     "sourceType": "competition"
    },
    {
     "datasetId": 7474089,
     "sourceId": 12156348,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 157.165756,
   "end_time": "2025-07-06T22:07:33.464889",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-06T22:04:56.299133",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
